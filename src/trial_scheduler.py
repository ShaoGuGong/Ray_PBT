import logging
import time
from datetime import UTC, datetime, timedelta
from pathlib import Path

import ray
from ray import ObjectRef
from ray.actor import ActorHandle

from .trial_state import TrialManager, TrialState
from .utils import WorkerType, colored_progress_bar, timing_block


def cpu_scheduling(
    trial_state: TrialState,
    cpu_workers: dict[int, ActorHandle],
    logger: logging.Logger | None = None,
) -> bool:
    available_futures: list = [
        worker.get_available_slots.remote() for worker in cpu_workers.values()
    ]

    available_cpu_workers = [
        worker
        for worker, available_slots in zip(
            cpu_workers.items(),
            ray.get(available_futures),
            strict=True,
        )  # type: ignore[reportGeneralTypeIssues]
        if available_slots
    ]

    if not available_cpu_workers:
        return False

    worker_id, worker = next(iter(available_cpu_workers))
    trial_state.worker_id = worker_id
    trial_state.worker_type = WorkerType.CPU
    trial_state.set_running()

    if worker_id == trial_state.last_checkpoint_location.worker_id:
        with timing_block(
            f"Assigning Trial {trial_state.id} snapshot to CPU Worker {worker_id}",
            logger=logger.info if logger else None,
        ):
            ray.get(worker.assign_trial.remote(trial_state.snapshot))  # type: ignore[reportGeneralTypeIssues]

    else:
        with timing_block(
            f"Assigning Trial {trial_state.id} to CPU Worker {worker_id}",
            logger=logger.info if logger else None,
        ):
            ray.get(worker.assign_trial.remote(trial_state))  # type: ignore[reportGeneralTypeIssues]

    return True


def gpu_scheduling(
    trial_state: TrialState,
    gpu_workers: dict[int, ActorHandle],
    logger: logging.Logger | None = None,
) -> bool:
    available_futures = [
        worker.get_available_slots.remote() for worker in gpu_workers.values()
    ]

    available_gpu_workers = [
        (worker, available_slots)
        for worker, available_slots in zip(
            gpu_workers.items(),
            ray.get(available_futures),  # type: ignore[reportGeneralTypeIssues]
            strict=True,
        )
        if available_slots
    ]

    if not available_gpu_workers:
        return False

    worker_id, worker = max(available_gpu_workers, key=lambda x: x[1])[0]
    trial_state.worker_id = worker_id
    trial_state.worker_type = WorkerType.GPU
    trial_state.set_running()

    if worker_id == trial_state.last_checkpoint_location.worker_id:
        with timing_block(
            f"Assigning Trial {trial_state.id} snapshot to GPU Worker {worker_id}",
            logger=logger.info if logger else None,
        ):
            ray.get(worker.assign_trial.remote(trial_state.snapshot))  # type: ignore[reportGeneralTypeIssues]
    else:
        with timing_block(
            f"Assigning Trial {trial_state.id} to GPU Worker {worker_id}",
            logger=logger.info if logger else None,
        ):
            ray.get(worker.assign_trial.remote(trial_state))  # type: ignore[reportGeneralTypeIssues]

    return True


def gpu_stealing_strategy(
    cpu_workers: list[ActorHandle],
    logger: logging.Logger,
) -> ObjectRef | None:
    available_futures: list = [
        worker.get_active_trials.remote() for worker in cpu_workers
    ]

    running_cpu_workers = [
        (worker, min(activate_trials, key=lambda x: x.iteration))
        for worker, activate_trials in zip(
            cpu_workers,
            ray.get(available_futures),  # type:int[reportGeneralTypeIssues]
            strict=True,
        )
        if len(activate_trials) > 0
    ]

    if running_cpu_workers:
        worker, trial_state = min(running_cpu_workers, key=lambda x: x[1].iteration)
        logger.info("å° Trial %d åŸ·è¡Œæ¶å¥ª", trial_state.id)
        ray.wait([worker.send_signal.remote(trial_state.id)], timeout=0.1)  # type: ignore[reportGeneralTypeIssues]


def get_trial_scheduler_logger() -> logging.Logger:
    """
    è¨­ç½®ä¸¦è¿”å›ä¸€å€‹æ—¥èªŒè¨˜éŒ„å™¨, ç”¨æ–¼è·Ÿè¸ªè¨“ç·´éç¨‹ä¸­çš„ TrialScheduler è¨˜éŒ„ã€‚

    æ—¥èªŒå°‡è¨˜éŒ„åˆ°ä¸€å€‹å¸¶æœ‰æ™‚é–“æˆ³çš„ç›®éŒ„ä¸­, ä¸¦åŒ…æ‹¬åœ¨çµ‚ç«¯é¡¯ç¤ºå’Œæ—¥èªŒæ–‡ä»¶ä¸­çš„è¨Šæ¯ã€‚

    Returns:
        logging.Logger: é…ç½®å¥½çš„ TrialScheduler è¨˜éŒ„å™¨ã€‚
    """
    timestamp = (datetime.now(UTC) + timedelta(hours=8)).strftime("%Y-%m-%d_%H-%M-%S")
    log_dir = Path.cwd() / "logs" / timestamp
    Path(log_dir).mkdir(parents=True, exist_ok=True)

    logger = logging.getLogger("trial_scheduler")

    if not logger.handlers:
        logger.setLevel(logging.DEBUG)  # æˆ–è€…é¸æ“‡æ›´åˆé©çš„ç´šåˆ¥

        formatter = logging.Formatter(
            "[%(asctime)s] %(levelname)s TRIAL_SCHEDULER -- %(message)s",
        )

        stream_handler = logging.StreamHandler()
        stream_handler.setLevel(logging.INFO)  # åªé¡¯ç¤º INFO ç´šåˆ¥ä»¥ä¸Šçš„è¨Šæ¯
        stream_handler.setFormatter(formatter)
        logger.addHandler(stream_handler)

        file_handler = logging.FileHandler(Path(log_dir) / "trial_scheduler.log")
        file_handler.setLevel(logging.DEBUG)  # è¨˜éŒ„æ‰€æœ‰ç´šåˆ¥çš„æ—¥èªŒ
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    return logger


class TrialScheduler:
    """
    è©¦é©—èª¿åº¦å™¨, è² è²¬ç®¡ç†å’Œåˆ†é…è¨“ç·´è©¦é©—çµ¦å¯ç”¨çš„å·¥ä½œè€…ã€‚

    Attributes:
        trial_states (List[TrialState]): ç•¶å‰å¾…åˆ†é…çš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        running_futures (List[ObjectRef]): ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™ã€‚
        completed_trial_state (List[TrialState]): å®Œæˆçš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        logger (logging.Logger): è¨˜éŒ„è¨“ç·´éç¨‹çš„æ—¥èªŒè¨˜éŒ„å™¨ã€‚
        train_result (TrainResult): ç”¨æ–¼è¨˜éŒ„æ¯å€‹è¨“ç·´çµæœçš„å¯¦ä¾‹ã€‚
        workers (List[ActorHandle]): å¯ç”¨çš„å·¥ä½œè€…åˆ—è¡¨ã€‚
    """

    def __init__(
        self,
        workers: dict[int, ActorHandle],
        trial_manager: TrialManager,
    ) -> None:
        """
        åˆå§‹åŒ– TrialScheduler, è¨­ç½®è©¦é©—ç‹€æ…‹å’Œå·¥ä½œè€…ã€‚

        Args:
            train_step (TrainStepFunction): è¨“ç·´æ­¥é©Ÿå‡½æ•¸ã€‚
            trial_states (List[TrialState]): åˆå§‹çš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        """
        self.trial_manager = trial_manager
        self.running_futures: list[ObjectRef] = []
        self.logger: logging.Logger = get_trial_scheduler_logger()
        self.workers: dict[int, ActorHandle] = workers
        self._previous_time: float = time.time()

        [worker.run.remote() for worker in self.workers.values()]

        self.gpu_workers: dict[int, ActorHandle] = {
            worker_id: worker
            for worker_id, worker in self.workers.items()
            if ray.get(worker.get_worker_type.remote()) == WorkerType.GPU  # type: ignore[reportGeneralTypeIssues]
        }

        self.cpu_workers = {
            worker_id: worker
            for worker_id, worker in self.workers.items()
            if ray.get(worker.get_worker_type.remote()) == WorkerType.CPU  # type:ignore[reportGeneralTypeIssues]
        }

        self.logger.info("åˆå§‹åŒ–å®Œæˆ")

    def assign_trial_to_worker(self) -> None:  # type: ignore[reportGeneralTypeIssues]
        """
        å°‡ä¸€å€‹è©¦é©—åˆ†é…çµ¦ä¸€å€‹å¯ç”¨çš„å·¥ä½œè€…ã€‚

        å¦‚æœæ‰€æœ‰å·¥ä½œè€…éƒ½å¿™ç¢Œ, å‰‡è¿”å›ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™ã€‚

        Returns:
            List[ObjectRef]: ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™åˆ—è¡¨ã€‚
        """
        uncompleted_trial_num = self.trial_manager.get_uncompleted_trial_num()
        if self.trial_manager.get_uncompleted_trial_num() < len(self.gpu_workers) * 3:
            self.logger.info(
                "ç•¶å‰æœªå®Œæˆçš„è©¦é©—æ•¸é‡: %d, å˜—è©¦åŸ·è¡Œæ¶å¥ª",
                uncompleted_trial_num,
            )
            gpu_stealing_strategy(list(self.cpu_workers.values()), logger=self.logger)

        else:
            # CPU Scheduling
            trial_state = self.trial_manager.get_kth_largest_iteration_trial(
                len(self.cpu_workers),
            )
            if trial_state is None:
                return

            trial_state.set_chunk_size(3)
            if cpu_scheduling(trial_state, self.cpu_workers, self.logger):
                self.trial_manager.run_trial(trial_state.id)
                self.trial_manager.update_trial(trial_state)

        # GPU Scheduling
        trial_state = self.trial_manager.get_least_iterated_pending_trial()
        if trial_state is None:
            return

        chunk_size = self.trial_manager.get_chunk_size(trial_state.iteration)  # type: ignore[reportGeneralTypeIssues]

        trial_state.set_chunk_size(chunk_size)
        if gpu_scheduling(trial_state, self.gpu_workers, self.logger):
            self.trial_manager.run_trial(trial_state.id)
            self.trial_manager.update_trial(trial_state)

    def run(self) -> None:
        """
        é–‹å§‹è¨“ç·´éç¨‹, å°‡è©¦é©—åˆ†é…çµ¦å·¥ä½œè€…ä¸¦è™•ç†å®Œæˆçš„çµæœã€‚

        è©²æ–¹æ³•æœƒæŒçºŒé‹è¡Œç›´åˆ°æ‰€æœ‰çš„è©¦é©—éƒ½å®Œæˆã€‚
        """
        self.logger.info("è¨“ç·´é–‹å§‹")
        update_assign_time = time.time()
        # while self.running_futures or self.pending_trial_states:
        while not self.trial_manager.is_finish():
            if (current_time := time.time()) - update_assign_time > 1.0:
                update_assign_time = current_time
                self.assign_trial_to_worker()

        self.print_iteration_count()
        self.logger.info("ğŸ‰ æ‰€æœ‰ Trial è¨“ç·´å®Œæˆ!")
        futures = [worker.stop.remote() for worker in self.workers.values()]
        ray.get(futures)  # type:ignore[reportGeneralTypeIssues]

    def print_iteration_count(self) -> None:
        iteration_counts = [
            (i.id, i.device_iteration_count)
            for i in self.trial_manager.all_trials.values()
        ]

        iteration_counts.sort(key=lambda x: x[0])

        for index, value in iteration_counts:
            self.logger.info(
                "Trial:%2d CPU/GPU %s",
                index,
                colored_progress_bar(
                    [value[WorkerType.CPU], value[WorkerType.GPU]],
                    40,
                ),
            )
        self.logger.info(
            "Total    CPU/GPU %s",
            colored_progress_bar(
                [
                    sum(i[1][WorkerType.CPU] for i in iteration_counts),
                    sum(i[1][WorkerType.GPU] for i in iteration_counts),
                ],
                40,
            ),
        )

    def get_workers_logs(self) -> None:
        """
        ç²å–æ‰€æœ‰å·¥ä½œè€…çš„æ—¥èªŒä¸¦å°‡å…¶ä¿å­˜åˆ°æ–‡ä»¶ä¸­ã€‚
        è©²æ–¹æ³•æœƒå°‡æ¯å€‹å·¥ä½œè€…çš„æ—¥èªŒå¯«å…¥åˆ°ç›¸æ‡‰çš„æ–‡ä»¶ä¸­ã€‚
        """
        log_dir = None
        for handler in self.logger.handlers:
            if isinstance(handler, logging.FileHandler):
                log_dir = Path(handler.baseFilename).parent  # å–å¾—è³‡æ–™å¤¾è·¯å¾‘
                break

        if log_dir is None:
            self.logger.error("logsæª”æ¡ˆè³‡æ–™å¤¾ä¸å­˜åœ¨")
            return

        for worker in self.workers.values():
            future = ray.get(worker.get_log_file.remote())  # type: ignore[reportGeneralTypeIssues]
            with (Path(log_dir) / f"worker-{future['id']}.log").open("w") as f:
                f.write(future["content"])
