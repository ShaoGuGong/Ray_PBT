import asyncio
import logging
import os
import time
from datetime import datetime
from typing import Any, List, Optional, Protocol

import ray
from ray import ObjectRef
from ray.actor import ActorHandle
from torch.nn.modules import activation

from .trial_state import TrialState
from .utils import TrialStatus, WorkerType, colored_progress_bar


class AssignTrialStrategy(Protocol):
    def __call__(
        self,
        trial_state: List[TrialState],
        gpu_workers: List[ActorHandle],
        cpu_workers: List[ActorHandle],
        *args: Any,
        **kwargs: Any,
    ) -> List[ObjectRef]: ...


def round_robin_strategy(
    pending_trial_states: List[TrialState],
    gpu_workers: List[ActorHandle],
    cpu_workers: List[ActorHandle],
) -> Optional[ObjectRef]:
    if not pending_trial_states:
        return None

    available_futures = [worker.get_available_slots.remote() for worker in gpu_workers]

    available_gpu_workers = [
        worker
        for worker, available_slots in zip(gpu_workers, ray.get(available_futures))
        if available_slots > 0
    ]

    if available_gpu_workers:
        worker = next(iter(available_gpu_workers))
        trial_state = min(pending_trial_states, key=lambda x: x.iteration)

        pending_trial_states.remove(trial_state)
        future = worker.assign_trial.remote(trial_state)

        return future

    available_futures = [worker.get_available_slots.remote() for worker in cpu_workers]

    available_cpu_workers = [
        worker
        for worker, available_slots in zip(cpu_workers, ray.get(available_futures))
        if available_slots
    ]

    if not available_cpu_workers:
        return None

    worker = next(iter(available_cpu_workers))
    trial_state = min(pending_trial_states, key=lambda x: x.iteration)

    pending_trial_states.remove(trial_state)
    future = worker.assign_trial.remote(trial_state)

    return future


def gpu_first_strategy(
    gpu_workers: List[ActorHandle],
    cpu_workers: List[ActorHandle],
    *args: Any,
) -> Optional[ObjectRef]:

    available_futures = [worker.get_available_slots.remote() for worker in gpu_workers]

    available_gpu_workers = [
        worker
        for worker, is_available in zip(gpu_workers, ray.get(available_futures))
        if is_available
    ]

    if not available_gpu_workers:
        return None

    available_futures = [worker.get_active_trials.remote() for worker in cpu_workers]

    running_cpu_workers = [
        (worker, min(activate_trials, key=lambda x: x.iteration))
        for worker, activate_trials in zip(gpu_workers, ray.get(available_futures))
        if len(activate_trials) > 0
    ]

    if running_cpu_workers:
        worker, trial_state = min(running_cpu_workers, key=lambda x: x[1].iteration)
        ray.get(worker.send_signal.remote(trial_state.id))


def get_trial_scheduler_logger() -> logging.Logger:
    """
    è¨­ç½®ä¸¦è¿”å›ä¸€å€‹æ—¥èªŒè¨˜éŒ„å™¨ï¼Œç”¨æ–¼è·Ÿè¸ªè¨“ç·´éç¨‹ä¸­çš„ TrialScheduler è¨˜éŒ„ã€‚

    æ—¥èªŒå°‡è¨˜éŒ„åˆ°ä¸€å€‹å¸¶æœ‰æ™‚é–“æˆ³çš„ç›®éŒ„ä¸­ï¼Œä¸¦åŒ…æ‹¬åœ¨çµ‚ç«¯é¡¯ç¤ºå’Œæ—¥èªŒæ–‡ä»¶ä¸­çš„è¨Šæ¯ã€‚

    Returns:
        logging.Logger: é…ç½®å¥½çš„ TrialScheduler è¨˜éŒ„å™¨ã€‚
    """
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    log_dir = os.path.join(os.getcwd(), "logs/", timestamp)
    os.makedirs(log_dir, exist_ok=True)

    logger = logging.getLogger(f"trial_scheduler")

    if not logger.handlers:
        logger.setLevel(logging.DEBUG)  # æˆ–è€…é¸æ“‡æ›´åˆé©çš„ç´šåˆ¥

        formatter = logging.Formatter(
            "[%(asctime)s] %(levelname)s TRIAL_SCHEDULER -- %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )

        stream_handler = logging.StreamHandler()
        stream_handler.setLevel(logging.INFO)  # åªé¡¯ç¤º INFO ç´šåˆ¥ä»¥ä¸Šçš„è¨Šæ¯
        stream_handler.setFormatter(formatter)
        logger.addHandler(stream_handler)

        file_handler = logging.FileHandler(
            os.path.join(log_dir, f"trial_scheduler.log")
        )
        file_handler.setLevel(logging.DEBUG)  # è¨˜éŒ„æ‰€æœ‰ç´šåˆ¥çš„æ—¥èªŒ
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    return logger


class TrialScheduler:
    """
    è©¦é©—èª¿åº¦å™¨ï¼Œè² è²¬ç®¡ç†å’Œåˆ†é…è¨“ç·´è©¦é©—çµ¦å¯ç”¨çš„å·¥ä½œè€…ã€‚

    Attributes:
        trial_states (List[TrialState]): ç•¶å‰å¾…åˆ†é…çš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        running_futures (List[ObjectRef]): ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™ã€‚
        completed_trial_state (List[TrialState]): å®Œæˆçš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        logger (logging.Logger): è¨˜éŒ„è¨“ç·´éç¨‹çš„æ—¥èªŒè¨˜éŒ„å™¨ã€‚
        train_result (TrainResult): ç”¨æ–¼è¨˜éŒ„æ¯å€‹è¨“ç·´çµæœçš„å¯¦ä¾‹ã€‚
        workers (List[ActorHandle]): å¯ç”¨çš„å·¥ä½œè€…åˆ—è¡¨ã€‚
    """

    def __init__(
        self,
        tuner: ActorHandle,
        workers: List[ActorHandle],
        trial_states: List[TrialState],
    ) -> None:
        """
        åˆå§‹åŒ– TrialSchedulerï¼Œè¨­ç½®è©¦é©—ç‹€æ…‹å’Œå·¥ä½œè€…ã€‚

        Args:
            train_step (TrainStepFunction): è¨“ç·´æ­¥é©Ÿå‡½æ•¸ã€‚
            trial_states (List[TrialState]): åˆå§‹çš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        """
        self.tuner = tuner

        self.pending_trial_states: List[TrialState] = trial_states
        self.completed_trial_states: List[TrialState] = []
        self.waiting_trial_states: List[TrialState] = []

        self.running_futures: List[ObjectRef] = []
        self.logger = get_trial_scheduler_logger()
        self.workers = workers
        self._previous_time = time.time()

        self.gpu_workers = [
            worker
            for worker in self.workers
            if ray.get(worker.get_worker_type.remote()) == WorkerType.GPU
        ]
        self.idle_gpu_count = 0

        self.cpu_workers = [
            worker
            for worker in self.workers
            if ray.get(worker.get_worker_type.remote()) == WorkerType.CPU
        ]

        self.logger.debug(f"{len(self.gpu_workers)=}")
        self.logger.debug(f"{len(self.cpu_workers)=}")

    def assign_trial_to_worker(self) -> List[ObjectRef]:
        """
        å°‡ä¸€å€‹è©¦é©—åˆ†é…çµ¦ä¸€å€‹å¯ç”¨çš„å·¥ä½œè€…ã€‚

        å¦‚æœæ‰€æœ‰å·¥ä½œè€…éƒ½å¿™ç¢Œï¼Œå‰‡è¿”å›ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™ã€‚

        Returns:
            List[ObjectRef]: ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™åˆ—è¡¨ã€‚
        """
        if self.pending_trial_states:
            pending_trial_list = sorted(
                self.pending_trial_states, key=lambda t: t.iteration
            )
            pending_trial_id_list = [i.id for i in pending_trial_list]
            self.logger.info(
                f"â³ ç­‰å¾…ä¸­è¨“ç·´ä»»å‹™åˆ—è¡¨é•·åº¦ï¼š{len(pending_trial_list):2d} <{pending_trial_list[0].iteration} - {pending_trial_list[-1].iteration}> {pending_trial_id_list}"
            )
            future = round_robin_strategy(
                pending_trial_states=self.pending_trial_states,
                gpu_workers=self.gpu_workers,
                cpu_workers=self.cpu_workers,
            )
            if future is not None:
                self.running_futures.append(future)
            return self.running_futures

        self.logger.info(f"â³ ç­‰å¾…è¨“ç·´ä»»å‹™åˆ—è¡¨é•·åº¦ï¼š0, åŸ·è¡Œ Trial æ¶å¥ª")
        gpu_first_strategy(self.gpu_workers, self.cpu_workers)

    def run(self):
        """
        é–‹å§‹è¨“ç·´éç¨‹ï¼Œå°‡è©¦é©—åˆ†é…çµ¦å·¥ä½œè€…ä¸¦è™•ç†å®Œæˆçš„çµæœã€‚

        è©²æ–¹æ³•æœƒæŒçºŒé‹è¡Œç›´åˆ°æ‰€æœ‰çš„è©¦é©—éƒ½å®Œæˆã€‚
        """
        self.logger.info("è¨“ç·´é–‹å§‹")
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        while self.running_futures or self.pending_trial_states:
            self.assign_trial_to_worker()

            if not self.running_futures and not self.pending_trial_states:
                break

            done_futures, self.running_futures = ray.wait(
                self.running_futures, timeout=2.0
            )

            if done_futures:
                loop.run_until_complete(self.handle_done_futures(done_futures))
                # asyncio.create_task(self.handle_done_futures(done_futures))

        iteration_counts = [
            (i.id, i.device_iteration_count) for i in self.completed_trial_states
        ]

        iteration_counts.sort(key=lambda x: x[0])

        for index, value in iteration_counts:
            print(
                f"Trial:{index:2} CPU/GPU",
                colored_progress_bar(
                    [value[WorkerType.CPU], value[WorkerType.GPU]], 40
                ),
            )

        print(
            f"Total   CPU/GPU",
            colored_progress_bar(
                [
                    sum(i[1][WorkerType.CPU] for i in iteration_counts),
                    sum(i[1][WorkerType.GPU] for i in iteration_counts),
                ],
                40,
            ),
        )

        self.logger.info("ğŸ‰ æ‰€æœ‰ Trial è¨“ç·´å®Œæˆï¼")

    def get_workers_logs(self) -> None:
        """
        ç²å–æ‰€æœ‰å·¥ä½œè€…çš„æ—¥èªŒä¸¦å°‡å…¶ä¿å­˜åˆ°æ–‡ä»¶ä¸­ã€‚

        è©²æ–¹æ³•æœƒå°‡æ¯å€‹å·¥ä½œè€…çš„æ—¥èªŒå¯«å…¥åˆ°ç›¸æ‡‰çš„æ–‡ä»¶ä¸­ã€‚
        """

        log_dir = None

        for handler in self.logger.handlers:
            if isinstance(handler, logging.FileHandler):
                log_dir = os.path.dirname(handler.baseFilename)  # å–å¾—è³‡æ–™å¤¾è·¯å¾‘
                break

        if log_dir is None:
            self.logger.error("logsæª”æ¡ˆè³‡æ–™å¤¾ä¸å­˜åœ¨")
            return

        for worker in self.workers:
            future = ray.get(worker.get_log_file.remote())
            with open(os.path.join(log_dir, f"worker-{future['id']}.log"), "w") as f:
                f.write(future["content"])

    async def handle_done_futures(self, done_futures: List[ObjectRef]):
        """
        è™•ç†å·²å®Œæˆçš„è¨“ç·´ä»»å‹™ï¼Œå°‡çµæœæ·»åŠ åˆ°å·²å®Œæˆè©¦é©—ç‹€æ…‹åˆ—è¡¨ä¸­ã€‚

        Args:
            done_futures (List[ObjectRef]): å·²å®Œæˆçš„è¨“ç·´ä»»å‹™åˆ—è¡¨ã€‚
        """

        for future in done_futures:
            try:
                trial_state: TrialState = ray.get(future)
                if trial_state.status == TrialStatus.TERMINATE:
                    self.completed_trial_states.append(trial_state)
                    self.logger.info(
                        f"âœ… Worker {trial_state.worker_id} Trial {trial_state.id} å®Œæˆï¼ŒAccuracy: {trial_state.accuracy:.1f}"
                    )
                    self.logger.info(
                        f"âœ… å·²å®Œæˆçš„è¨“ç·´ä»»å‹™åˆ—è¡¨: {sorted([i.id for i in self.completed_trial_states])}"
                    )

                elif trial_state.status == TrialStatus.PAUSE:
                    trial_state.status = TrialStatus.PENDING
                    self.pending_trial_states.append(trial_state)
                    self.logger.info(
                        f"ğŸ”ƒ Worker {trial_state.worker_id} å›å‚³æœªå®Œæˆ Trial {trial_state.id}, Iteration: {trial_state.iteration} ï¼ŒAccuracy: {trial_state.accuracy:.2f}"
                    )
                    trial_state = ray.get(self.tuner.mutation.remote(trial_state))

                elif trial_state.status == TrialStatus.PENDING:
                    self.pending_trial_states.append(trial_state)
                    self.logger.warning(f"â—ç™¼ç”Ÿç¢°æ’, å›å‚³ Trial {trial_state.id}")

                trial_state.worker_id = -1
                trial_state.worker_type = None
                self.tuner.record_trial_progress.remote(trial_state)
            except Exception as e:
                self.logger.error(f"âŒ Future åŸ·è¡Œå¤±æ•—: {e}")
