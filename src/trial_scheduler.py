import logging
import time
from datetime import datetime
from pathlib import Path
from typing import Any, List, Optional, Protocol

import ray
from ray import ObjectRef
from ray.actor import ActorHandle

from .config import PHASE_ITERATION, STOP_ITERATION
from .trial_phase import TrialPhase
from .trial_state import TrialState
from .utils import TrialStatus, WorkerType, colored_progress_bar


class AssignTrialStrategy(Protocol):
    def __call__(
        self,
        trial_state: List[TrialState],
        gpu_workers: List[ActorHandle],
        cpu_workers: List[ActorHandle],
        *args: Any,
        **kwargs: Any,
    ) -> List[ObjectRef]: ...


def cpu_scheduling(
    pending_trial_states: List[TrialState],
    cpu_workers: List[ActorHandle],
    trial_phase: TrialPhase,
) -> None:
    if not pending_trial_states:
        return

    available_futures = [worker.get_available_slots.remote() for worker in cpu_workers]

    available_cpu_workers = [
        worker
        for worker, available_slots in zip(cpu_workers, ray.get(available_futures))  # type: ignore[reportGeneralTypeIssues]
        if available_slots
    ]

    if not available_cpu_workers:
        return

    available_trials = [
        trial
        for trial in pending_trial_states
        if trial.phase <= trial_phase.current_phase
    ]

    if not available_trials:
        return

    trial_state = max(available_trials, key=lambda x: x.iteration)
    worker = next(iter(available_cpu_workers))
    pending_trial_states.remove(trial_state)
    ray.get(worker.assign_trial.remote(trial_state))  # type: ignore[reportGeneralTypeIssues]


def gpu_scheduling(
    pending_trial_states: List[TrialState],
    gpu_workers: List[ActorHandle],
) -> None:
    if not pending_trial_states:
        return

    available_futures = [worker.get_available_slots.remote() for worker in gpu_workers]

    available_gpu_workers = [
        (worker, available_slots)
        for worker, available_slots in zip(gpu_workers, ray.get(available_futures))  # type: ignore[reportGeneralTypeIssues]
        if available_slots
    ]

    if not available_gpu_workers:
        return

    worker = max(available_gpu_workers, key=lambda x: x[1])[0]
    trial_state = min(pending_trial_states, key=lambda x: x.iteration)

    pending_trial_states.remove(trial_state)
    ray.get(worker.assign_trial.remote(trial_state))  # type: ignore[reportGeneralTypeIssues]


def round_robin_strategy(
    pending_trial_states: List[TrialState],
    gpu_workers: List[ActorHandle],
    cpu_workers: List[ActorHandle],
    trial_phase: TrialPhase,
) -> None:
    if not pending_trial_states:
        return

    # Assign to CPU
    available_futures = [worker.get_available_slots.remote() for worker in cpu_workers]

    available_cpu_workers = [
        worker
        for worker, available_slots in zip(cpu_workers, ray.get(available_futures))  # type: ignore[reportGeneralTypeIssues]
        if available_slots
    ]

    if available_cpu_workers:
        worker = next(iter(available_cpu_workers))
        available_trials = [
            trial
            for trial in pending_trial_states
            if trial.phase <= trial_phase.current_phase
        ]

        if available_trials:
            trial_state = max(
                available_trials,
                key=lambda x: x.iteration,
            )

            pending_trial_states.remove(trial_state)
            worker.assign_trial.remote(trial_state)
            return

    # Assign to GPU
    available_futures = [worker.get_available_slots.remote() for worker in gpu_workers]

    available_gpu_workers = [
        (worker, available_slots)
        for worker, available_slots in zip(gpu_workers, ray.get(available_futures))  # type: ignore[reportGeneralTypeIssues]
        if available_slots
    ]

    if available_gpu_workers:
        worker = max(available_gpu_workers, key=lambda x: x[1])[0]
        trial_state = min(pending_trial_states, key=lambda x: x.iteration)

        pending_trial_states.remove(trial_state)
        worker.assign_trial.remote(trial_state)


def gpu_stealing_strategy(
    cpu_workers: List[ActorHandle],
    **kargs: Any,
) -> Optional[ObjectRef]:
    logger = kargs["logger"]

    available_futures = [worker.get_active_trials.remote() for worker in cpu_workers]

    running_cpu_workers = [
        (worker, min(activate_trials, key=lambda x: x.iteration))
        for worker, activate_trials in zip(cpu_workers, ray.get(available_futures))  # type: ignore[reportGeneralTypeIssues]
        if len(activate_trials) > 0
    ]

    if running_cpu_workers:
        worker, trial_state = min(running_cpu_workers, key=lambda x: x[1].iteration)
        logger.info(f"å° Trial {trial_state.id} åŸ·è¡Œæ¶å¥ª")
        ray.wait([worker.send_signal.remote(trial_state.id)], timeout=0.1)  # type: ignore[reportGeneralTypeIssues]


def get_trial_scheduler_logger() -> logging.Logger:
    """
    è¨­ç½®ä¸¦è¿”å›ä¸€å€‹æ—¥èªŒè¨˜éŒ„å™¨ï¼Œç”¨æ–¼è·Ÿè¸ªè¨“ç·´éç¨‹ä¸­çš„ TrialScheduler è¨˜éŒ„ã€‚

    æ—¥èªŒå°‡è¨˜éŒ„åˆ°ä¸€å€‹å¸¶æœ‰æ™‚é–“æˆ³çš„ç›®éŒ„ä¸­ï¼Œä¸¦åŒ…æ‹¬åœ¨çµ‚ç«¯é¡¯ç¤ºå’Œæ—¥èªŒæ–‡ä»¶ä¸­çš„è¨Šæ¯ã€‚

    Returns:
        logging.Logger: é…ç½®å¥½çš„ TrialScheduler è¨˜éŒ„å™¨ã€‚
    """
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    log_dir = Path.cwd() / "logs" / timestamp
    Path(log_dir).mkdir(parents=True, exist_ok=True)

    logger = logging.getLogger("trial_scheduler")

    if not logger.handlers:
        logger.setLevel(logging.DEBUG)  # æˆ–è€…é¸æ“‡æ›´åˆé©çš„ç´šåˆ¥

        formatter = logging.Formatter(
            "[%(asctime)s] %(levelname)s TRIAL_SCHEDULER -- %(message)s",
        )

        stream_handler = logging.StreamHandler()
        stream_handler.setLevel(logging.INFO)  # åªé¡¯ç¤º INFO ç´šåˆ¥ä»¥ä¸Šçš„è¨Šæ¯
        stream_handler.setFormatter(formatter)
        logger.addHandler(stream_handler)

        file_handler = logging.FileHandler(Path(log_dir) / "trial_scheduler.log")
        file_handler.setLevel(logging.DEBUG)  # è¨˜éŒ„æ‰€æœ‰ç´šåˆ¥çš„æ—¥èªŒ
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    return logger


class TrialScheduler:
    """
    è©¦é©—èª¿åº¦å™¨ï¼Œè² è²¬ç®¡ç†å’Œåˆ†é…è¨“ç·´è©¦é©—çµ¦å¯ç”¨çš„å·¥ä½œè€…ã€‚

    Attributes:
        trial_states (List[TrialState]): ç•¶å‰å¾…åˆ†é…çš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        running_futures (List[ObjectRef]): ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™ã€‚
        completed_trial_state (List[TrialState]): å®Œæˆçš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        logger (logging.Logger): è¨˜éŒ„è¨“ç·´éç¨‹çš„æ—¥èªŒè¨˜éŒ„å™¨ã€‚
        train_result (TrainResult): ç”¨æ–¼è¨˜éŒ„æ¯å€‹è¨“ç·´çµæœçš„å¯¦ä¾‹ã€‚
        workers (List[ActorHandle]): å¯ç”¨çš„å·¥ä½œè€…åˆ—è¡¨ã€‚
    """

    def __init__(
        self,
        tuner: ActorHandle,
        workers: List[ActorHandle],
        trial_states: List[TrialState],
    ) -> None:
        """
        åˆå§‹åŒ– TrialSchedulerï¼Œè¨­ç½®è©¦é©—ç‹€æ…‹å’Œå·¥ä½œè€…ã€‚

        Args:
            train_step (TrainStepFunction): è¨“ç·´æ­¥é©Ÿå‡½æ•¸ã€‚
            trial_states (List[TrialState]): åˆå§‹çš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        """
        self.tuner = tuner
        self.trial_phase = TrialPhase(STOP_ITERATION, PHASE_ITERATION)

        self.pending_trial_states: List[TrialState] = trial_states
        self.completed_trial_states: List[TrialState] = []
        self.waiting_trial_states: List[TrialState] = []
        self.trial_state_nums: int = len(self.pending_trial_states)

        self.running_futures: List[ObjectRef] = []
        self.logger: logging.Logger = get_trial_scheduler_logger()
        self.workers: List[ActorHandle] = workers
        self._previous_time: float = time.time()
        self.is_final_phase: bool = False

        ray.wait([worker.run.remote() for worker in self.workers], timeout=0.1)  # type: ignore[reportGeneralTypeIssues]

        self.gpu_workers = [
            worker
            for worker in self.workers
            if ray.get(worker.get_worker_type.remote()) == WorkerType.GPU  # type: ignore[reportGeneralTypeIssues]
        ]
        self.cpu_workers = [
            worker
            for worker in self.workers
            if ray.get(worker.get_worker_type.remote()) == WorkerType.CPU  # type:ignore[reportGeneralTypeIssues]
        ]

        self.logger.info("åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"{len(self.gpu_workers)=}")
        self.logger.info(f"{len(self.cpu_workers)=}")

    def assign_trial_to_worker(self) -> None:  # type: ignore[reportGeneralTypeIssues]
        """
        å°‡ä¸€å€‹è©¦é©—åˆ†é…çµ¦ä¸€å€‹å¯ç”¨çš„å·¥ä½œè€…ã€‚

        å¦‚æœæ‰€æœ‰å·¥ä½œè€…éƒ½å¿™ç¢Œï¼Œå‰‡è¿”å›ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™ã€‚

        Returns:
            List[ObjectRef]: ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™åˆ—è¡¨ã€‚
        """

        if not self.is_final_phase and (
            self.trial_state_nums - len(self.completed_trial_states)
        ) < (len(self.gpu_workers) * 4 + len(self.cpu_workers)):
            self.logger.info("å·²åˆ°æœ€å¾Œéšæ®µ é–‹å§‹åŸ·è¡Œæ¶å¥ª")
            self.is_final_phase = True

        # if self.pending_trial_states:
        #     pending_trial_list = sorted(
        #         self.pending_trial_states, key=lambda t: t.iteration
        #     )
        #     pending_trial_id_list = [i.id for i in pending_trial_list]
        #     self.logger.info(
        #         f"â³ ç­‰å¾…ä¸­è¨“ç·´ä»»å‹™åˆ—è¡¨é•·åº¦ï¼š{len(pending_trial_list):2d}, "
        #         f"{pending_trial_id_list}"
        #     )

        if not self.is_final_phase:
            cpu_scheduling(
                self.pending_trial_states,
                self.cpu_workers,
                self.trial_phase,
            )
            gpu_scheduling(self.pending_trial_states, self.gpu_workers)

        else:
            gpu_scheduling(self.pending_trial_states, self.gpu_workers)
            gpu_stealing_strategy(self.cpu_workers, logger=self.logger)

    def submit_trial(self, trial_state: TrialState) -> None:
        status = trial_state.status

        if status == TrialStatus.INTERRUPTED:
            trial_state.status = TrialStatus.PENDING
            self.pending_trial_states.append(trial_state)
            self.logger.info(
                f"ğŸ”ƒ Worker {trial_state.worker_id} å›å‚³å·²ä¸­æ–· Trial {trial_state.id}",
            )

        if status == TrialStatus.PAUSE:
            trial_state.status = TrialStatus.PENDING
            self.pending_trial_states.append(trial_state)
            self.logger.info(
                f"ğŸ”ƒ Worker {trial_state.worker_id} å›å‚³æœªå®Œæˆ Trial {trial_state.id}, "
                f"Iteration: {trial_state.iteration}ï¼Œ"
                f"Accuracy: {trial_state.accuracy:.2f}",
            )

        elif status == TrialStatus.NEED_MUTATION:
            trial_state = ray.get(self.tuner.mutation.remote(trial_state))  # type: ignore[reportGeneralTypeIssues]
            if trial_state.checkpoint is None:
                self.logger.debug(f"Trial {trial_state.id} checkpoint is None")
            trial_state.status = TrialStatus.PENDING
            self.pending_trial_states.append(trial_state)

        elif status == TrialStatus.TERMINATE:
            self.completed_trial_states.append(trial_state)
            self.logger.info(
                "âœ… Worker %d Trial %d å®Œæˆï¼ŒAccuracy: %.2f",
                trial_state.worker_id,
                trial_state.id,
                trial_state.accuracy,
            )
            self.logger.info(
                f"âœ… å·²å®Œæˆçš„è¨“ç·´ä»»å‹™åˆ—è¡¨: {sorted([i.id for i in self.completed_trial_states])}",
            )

        elif status == TrialStatus.FAILED:
            self.completed_trial_states.append(trial_state)
            self.logger.warning(
                "Worker %d Trial %d  ç™¼ç”ŸéŒ¯èª¤, å·²ä¸­æ­¢è¨“ç·´",
                trial_state.worker_id,
                trial_state.id,
            )

        trial_state.worker_id = -1
        trial_state.worker_type = None
        self.tuner.record_trial_progress.remote(trial_state.without_checkpoint())

    def run(self) -> None:
        """
        é–‹å§‹è¨“ç·´éç¨‹ï¼Œå°‡è©¦é©—åˆ†é…çµ¦å·¥ä½œè€…ä¸¦è™•ç†å®Œæˆçš„çµæœã€‚

        è©²æ–¹æ³•æœƒæŒçºŒé‹è¡Œç›´åˆ°æ‰€æœ‰çš„è©¦é©—éƒ½å®Œæˆã€‚
        """
        self.logger.info("è¨“ç·´é–‹å§‹")
        update_phase_time = time.time()
        # while self.running_futures or self.pending_trial_states:
        while len(self.completed_trial_states) < self.trial_state_nums:
            self.assign_trial_to_worker()

            if current_time := time.time() - update_phase_time > 60.0:
                self.update_phase()
                update_phase_time = current_time

        self.print_iteration_count()
        self.logger.info("ğŸ‰ æ‰€æœ‰ Trial è¨“ç·´å®Œæˆï¼")
        futures = [worker.stop.remote() for worker in self.workers]
        ray.get(futures)  # type:ignore[reportGeneralTypeIssues]

    def print_iteration_count(self) -> None:
        iteration_counts = [
            (i.id, i.device_iteration_count) for i in self.completed_trial_states
        ]

        iteration_counts.sort(key=lambda x: x[0])

        for index, value in iteration_counts:
            print(
                f"Trial:{index:2} CPU/GPU",
                colored_progress_bar(
                    [value[WorkerType.CPU], value[WorkerType.GPU]],
                    40,
                ),
            )

        print(
            "Total    CPU/GPU",
            colored_progress_bar(
                [
                    sum(i[1][WorkerType.CPU] for i in iteration_counts),
                    sum(i[1][WorkerType.GPU] for i in iteration_counts),
                ],
                40,
            ),
        )

    def get_workers_logs(self) -> None:
        """
        ç²å–æ‰€æœ‰å·¥ä½œè€…çš„æ—¥èªŒä¸¦å°‡å…¶ä¿å­˜åˆ°æ–‡ä»¶ä¸­ã€‚
        è©²æ–¹æ³•æœƒå°‡æ¯å€‹å·¥ä½œè€…çš„æ—¥èªŒå¯«å…¥åˆ°ç›¸æ‡‰çš„æ–‡ä»¶ä¸­ã€‚
        """
        log_dir = None
        for handler in self.logger.handlers:
            if isinstance(handler, logging.FileHandler):
                log_dir = Path(handler.baseFilename).parent  # å–å¾—è³‡æ–™å¤¾è·¯å¾‘
                break

        if log_dir is None:
            self.logger.error("logsæª”æ¡ˆè³‡æ–™å¤¾ä¸å­˜åœ¨")
            return

        for worker in self.workers:
            future = ray.get(worker.get_log_file.remote())  # type: ignore[reportGeneralTypeIssues]
            with (Path(log_dir) / f"worker-{future['id']}.log").open("w") as f:
                f.write(future["content"])

    def update_phase(self) -> None:
        old = self.trial_phase.current_phase
        self.trial_phase.update_phase(ray.get(self.tuner.get_trial_progress.remote()))  # type: ignore[reportGeneralTypeIssues]

        if old != self.trial_phase.current_phase:
            self.logger.info("æ›´æ–°éšæ®µåˆ°Phase %d", self.trial_phase.current_phase)
            futures = [
                worker.update_phase.remote(self.trial_phase.current_phase)
                for worker in self.workers
            ]
            ray.wait(futures, timeout=0.1)  # type: ignore[reportGeneralTypeIssues]
