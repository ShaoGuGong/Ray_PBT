import logging
import time
from datetime import UTC, datetime, timedelta
from pathlib import Path
from typing import TYPE_CHECKING

import ray
from ray import ObjectRef
from ray.actor import ActorHandle

from .utils import WorkerType
from .worker_manager import WorkerManager

if TYPE_CHECKING:
    from .trial_state import TrialState


def gpu_scheduling(
    trial_manager: ActorHandle,
    worker_manager: WorkerManager,
    logger: logging.Logger,
) -> None:
    # è‹¥æ²’æœ‰ä»»ä½• pending çš„ Trial,çµæŸ
    if not ray.get(trial_manager.has_pending_trials.remote()):  # type: ignore[reportGeneralTypeIssues]
        logger.info("æ²’æœ‰å¾…åˆ†é…çš„ Trial")
        return

    available_worker_entries = worker_manager.get_avaiable_gpu_workers()

    if not available_worker_entries:
        logger.info("æ²’æœ‰å¯ç”¨çš„ GPU worker")
        return

    # é¸æ“‡æ“æœ‰æœ€å¤š slot çš„ GPU worker ä½œç‚ºç›®æ¨™ worker
    selected_worker_entry = max(
        available_worker_entries,
        key=lambda e: e.available_slots,
    )

    # å–å¾— iteration æ¬¡æ•¸æœ€å°‘çš„ä¸€çµ„ pending trials
    trial_states: list[TrialState] = ray.get(
        trial_manager.get_pending_trials_with_min_iteration.remote(),  # type: ignore[reportGeneralTypeIssues]
    )

    # å„ªå…ˆæŒ‘é¸ä¹‹å‰æ›¾ç¶“åœ¨è©² worker ä¸Šæœ‰ checkpoint çš„ trial
    selected_trial = next(
        (
            t
            for t in trial_states
            if not t.last_checkpoint_location.is_empty()
            and t.last_checkpoint_location.worker_id == selected_worker_entry.id
        ),
        trial_states[0],  # è‹¥ç„¡ç¬¦åˆè€…, å‰‡é¸ç¬¬ä¸€å€‹
    )

    # è¨­å®š chunk_sizeã€worker_idã€worker_type ä¸¦æ¨™è¨˜ç‚ºåŸ·è¡Œç‹€æ…‹
    selected_trial.set_chunk_size(
        ray.get(trial_manager.get_chunk_size.remote(selected_trial.iteration)),  # type: ignore[reportGeneralTypeIssues]
    )
    selected_trial.worker_id = selected_worker_entry.id
    selected_trial.worker_type = WorkerType.GPU
    selected_trial.set_waiting()

    trial_manager.transition_to_waiting.remote(selected_trial.id)
    trial_manager.update_trial.remote(selected_trial)

    worker_manager.assign_trial_to_worker(
        selected_worker_entry.id,
        selected_trial,
    )


def cpu_scheduling(
    trial_manager: ActorHandle,
    worker_manager: WorkerManager,
    logger: logging.Logger,
) -> None:
    # è‹¥æ²’æœ‰ä»»ä½• pending çš„ Trial,çµæŸ
    if not ray.get(trial_manager.has_pending_trials.remote()):  # type: ignore[reportGeneralTypeIssues]
        logger.info("æ²’æœ‰å¾…åˆ†é…çš„ Trial")
        return

    available_worker_entries = worker_manager.get_avaiable_cpu_workers()

    if not available_worker_entries:
        logger.info("æ²’æœ‰å¯ç”¨çš„ CPU worker")
        return

    # é¸æ“‡ç¬¬ä¸€å€‹å¯ç”¨çš„ worker
    selected_worker_entry = available_worker_entries[0]

    # å–å¾— iteration è¼ƒé«˜çš„ Trials, å€‹æ•¸ç‚º CPU æ•¸
    # trial_states = ray.get(
    #     trial_manager.get_nlargest_iteration_trials.remote(  # type: ignore[reportGeneralTypeIssues]
    #         int(len(worker_manager.cpu_workers) + 3),
    #     ),
    # )
    # trial_states = trial_states[3:]
    #
    # if trial_states is None or not trial_states:
    #     return
    #
    # # å„ªå…ˆé¸æ“‡ checkpoint ä¾†è‡ªè©² worker çš„ trial, å¦å‰‡é¸æœ€å¾Œä¸€å€‹(iteration æœ€å°)
    # selected_trial = next(
    #     (
    #         t
    #         for t in trial_states
    #         if not t.last_checkpoint_location.is_empty()
    #         and t.last_checkpoint_location.worker_id == selected_worker_entry.id
    #     ),
    #     trial_states[-1],
    # )

    selected_trial = ray.get(trial_manager.get_nlargest_iteration_trial.remote())  # type: ignore[reportGeneralTypeIssues]

    if selected_trial:
        return

    selected_trial = selected_trial[-1]
    # è¨­å®š chunk_size(æš«å®šç‚º 2), æ¨™è¨˜åŸ·è¡Œè³‡è¨Š
    selected_trial.set_chunk_size(2)
    selected_trial.worker_id = selected_worker_entry.id
    selected_trial.worker_type = WorkerType.CPU
    selected_trial.set_waiting()

    # æ›´æ–° Trial ç‹€æ…‹è‡³ running
    trial_manager.transition_to_waiting.remote(selected_trial.id)
    trial_manager.update_trial.remote(selected_trial)

    worker_manager.assign_trial_to_worker(
        selected_worker_entry.id,
        selected_trial,
    )


def stealing_strategy(
    worker_manager: WorkerManager,
    logger: logging.Logger,
) -> None:
    logger.info("å˜—è©¦å¾ CPU Worker å·å–ä»»å‹™")
    running_workers = (
        worker_entry
        for worker_entry in worker_manager.cpu_workers.values()
        if worker_entry.available_slots == 0
    )

    worker = next(running_workers, None)
    if worker is None:
        logger.info("æ²’æœ‰å¯ç”¨çš„ CPU Worker ä¾†å·å–ä»»å‹™")
        return

    logger.info("å˜—è©¦å¾ CPU Worker %d å·å–ä»»å‹™", worker.id)
    worker.ref.stealing_trial.remote(worker.active_trials[0])  # type: ignore[reportGeneralTypeIssues])


def get_trial_scheduler_logger() -> logging.Logger:
    """
    è¨­ç½®ä¸¦è¿”å›ä¸€å€‹æ—¥èªŒè¨˜éŒ„å™¨, ç”¨æ–¼è·Ÿè¸ªè¨“ç·´éç¨‹ä¸­çš„ TrialScheduler è¨˜éŒ„ã€‚

    æ—¥èªŒå°‡è¨˜éŒ„åˆ°ä¸€å€‹å¸¶æœ‰æ™‚é–“æˆ³çš„ç›®éŒ„ä¸­, ä¸¦åŒ…æ‹¬åœ¨çµ‚ç«¯é¡¯ç¤ºå’Œæ—¥èªŒæ–‡ä»¶ä¸­çš„è¨Šæ¯ã€‚

    Returns:
        logging.Logger: é…ç½®å¥½çš„ TrialScheduler è¨˜éŒ„å™¨ã€‚
    """
    timestamp = (datetime.now(UTC) + timedelta(hours=8)).strftime("%Y-%m-%d_%H-%M-%S")
    log_dir = Path.cwd() / "logs" / timestamp
    Path(log_dir).mkdir(parents=True, exist_ok=True)

    logger = logging.getLogger("trial_scheduler")

    if not logger.handlers:
        logger.setLevel(logging.DEBUG)  # æˆ–è€…é¸æ“‡æ›´åˆé©çš„ç´šåˆ¥

        formatter = logging.Formatter(
            "[%(asctime)s] %(levelname)s TRIAL_SCHEDULER -- %(message)s",
        )

        stream_handler = logging.StreamHandler()
        stream_handler.setLevel(logging.INFO)  # åªé¡¯ç¤º INFO ç´šåˆ¥ä»¥ä¸Šçš„è¨Šæ¯
        stream_handler.setFormatter(formatter)
        logger.addHandler(stream_handler)

        file_handler = logging.FileHandler(Path(log_dir) / "trial_scheduler.log")
        file_handler.setLevel(logging.DEBUG)  # è¨˜éŒ„æ‰€æœ‰ç´šåˆ¥çš„æ—¥èªŒ
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    return logger


class TrialScheduler:
    """
    è©¦é©—èª¿åº¦å™¨, è² è²¬ç®¡ç†å’Œåˆ†é…è¨“ç·´è©¦é©—çµ¦å¯ç”¨çš„å·¥ä½œè€…ã€‚

    Attributes:
        trial_states (List[TrialState]): ç•¶å‰å¾…åˆ†é…çš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        running_futures (List[ObjectRef]): ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™ã€‚
        completed_trial_state (List[TrialState]): å®Œæˆçš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        logger (logging.Logger): è¨˜éŒ„è¨“ç·´éç¨‹çš„æ—¥èªŒè¨˜éŒ„å™¨ã€‚
        train_result (TrainResult): ç”¨æ–¼è¨˜éŒ„æ¯å€‹è¨“ç·´çµæœçš„å¯¦ä¾‹ã€‚
        workers (List[ActorHandle]): å¯ç”¨çš„å·¥ä½œè€…åˆ—è¡¨ã€‚
    """

    def __init__(
        self,
        worker_manager: WorkerManager,
        trial_manager: ActorHandle,
    ) -> None:
        """
        åˆå§‹åŒ– TrialScheduler, è¨­ç½®è©¦é©—ç‹€æ…‹å’Œå·¥ä½œè€…ã€‚

        Args:
            train_step (TrainStepFunction): è¨“ç·´æ­¥é©Ÿå‡½æ•¸ã€‚
            trial_states (List[TrialState]): åˆå§‹çš„è©¦é©—ç‹€æ…‹åˆ—è¡¨ã€‚
        """
        self.trial_manager = trial_manager
        self.worker_manager = worker_manager

        self.running_futures: list[ObjectRef] = []
        self.logger: logging.Logger = get_trial_scheduler_logger()

        self._previous_time: float = time.time()
        self.logger.info("åˆå§‹åŒ–å®Œæˆ")

    def assign_trial_to_worker(self) -> None:  # type: ignore[reportGeneralTypeIssues]
        """
        å°‡ä¸€å€‹è©¦é©—åˆ†é…çµ¦ä¸€å€‹å¯ç”¨çš„å·¥ä½œè€…ã€‚

        å¦‚æœæ‰€æœ‰å·¥ä½œè€…éƒ½å¿™ç¢Œ, å‰‡è¿”å›ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™ã€‚

        Returns:
            List[ObjectRef]: ç•¶å‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´ä»»å‹™åˆ—è¡¨ã€‚
        """

        if (
            ray.get(
                self.trial_manager.get_uncompleted_trial_num.remote(),  # type: ignore[reportGeneralTypeIssues]
            )
            <= len(self.worker_manager.gpu_workers) * 3
        ):
            stealing_strategy(self.worker_manager, self.logger)
        else:
            cpu_scheduling(self.trial_manager, self.worker_manager, self.logger)
        gpu_scheduling(self.trial_manager, self.worker_manager, self.logger)

    def run(self) -> None:
        """
        é–‹å§‹è¨“ç·´éç¨‹, å°‡è©¦é©—åˆ†é…çµ¦å·¥ä½œè€…ä¸¦è™•ç†å®Œæˆçš„çµæœã€‚

        è©²æ–¹æ³•æœƒæŒçºŒé‹è¡Œç›´åˆ°æ‰€æœ‰çš„è©¦é©—éƒ½å®Œæˆã€‚
        """
        self.logger.info("è¨“ç·´é–‹å§‹")
        update_assign_time = time.time()
        is_finish = False

        while not is_finish:
            iterval_time = 1.0
            if (current_time := time.time()) - update_assign_time > iterval_time:
                update_assign_time = current_time
                self.assign_trial_to_worker()

            is_finish = ray.get(self.trial_manager.is_finish.remote())  # type: ignore[reportGeneralTypeIssues]

        self.trial_manager.print_iteration_count.remote()
        self.logger.info("ğŸ‰ æ‰€æœ‰ Trial è¨“ç·´å®Œæˆ!")
        self.worker_manager.stop_all_workers()

    def get_workers_logs(self) -> None:
        """
        ç²å–æ‰€æœ‰å·¥ä½œè€…çš„æ—¥èªŒä¸¦å°‡å…¶ä¿å­˜åˆ°æ–‡ä»¶ä¸­ã€‚
        è©²æ–¹æ³•æœƒå°‡æ¯å€‹å·¥ä½œè€…çš„æ—¥èªŒå¯«å…¥åˆ°ç›¸æ‡‰çš„æ–‡ä»¶ä¸­ã€‚
        """
        log_dir = None
        for handler in self.logger.handlers:
            if isinstance(handler, logging.FileHandler):
                log_dir = Path(handler.baseFilename).parent  # å–å¾—è³‡æ–™å¤¾è·¯å¾‘
                break

        if log_dir is None:
            self.logger.error("logsæª”æ¡ˆè³‡æ–™å¤¾ä¸å­˜åœ¨")
            return

        for worker_entry in self.worker_manager.workers.values():
            worker = worker_entry.ref

            future = ray.get(worker.get_log_file.remote())  # type: ignore[reportGeneralTypeIssues]
            with (Path(log_dir) / f"worker-{future['id']}.log").open("w") as f:
                f.write(future["content"])
